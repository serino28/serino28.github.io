---
layout: default
title: "Research"
---

<section class="research-hero container">
    <span class="research-badge">ðŸš§ Work in Progress</span>
    <h1>Research Notes</h1>
    <p class="hero-description" style="max-width: 700px; margin: 0 auto;">
        Deep dives into mechanistic interpretability, sparse autoencoders, and understanding how language models think.
        Coming soon.
    </p>
</section>

<section class="container" style="padding-bottom: 100px;">
    <div class="research-grid">

        <!-- Placeholder Card 1 -->
        <article class="glass-card research-card" data-anim>
            <div class="research-card-content">
                <div class="research-card-date">Coming Soon</div>
                <h3 class="research-card-title">Understanding Sparse Autoencoders</h3>
                <p class="research-card-excerpt">
                    An introduction to SAEs and why they're becoming a key tool for mechanistic interpretability
                    research.
                    We'll explore how to train them, what they learn, and how to evaluate feature quality.
                </p>
                <div class="project-tags">
                    <span class="tag">Interpretability</span>
                    <span class="tag">SAE</span>
                    <span class="tag">Tutorial</span>
                </div>
            </div>
        </article>

        <!-- Placeholder Card 2 -->
        <article class="glass-card research-card" data-anim data-anim-delay="1">
            <div class="research-card-content">
                <div class="research-card-date">Coming Soon</div>
                <h3 class="research-card-title">Auto-Interpretability: Promise and Pitfalls</h3>
                <p class="research-card-excerpt">
                    Using LLMs to explain other neural networks sounds great in theory.
                    Here's what actually works, what doesn't, and how SFAL helps evaluate it.
                </p>
                <div class="project-tags">
                    <span class="tag">Auto-Interp</span>
                    <span class="tag">Evaluation</span>
                    <span class="tag">SFAL</span>
                </div>
            </div>
        </article>

        <!-- Placeholder Card 3 -->
        <article class="glass-card research-card" data-anim data-anim-delay="2">
            <div class="research-card-content">
                <div class="research-card-date">Coming Soon</div>
                <h3 class="research-card-title">Toxic Feature Detection in LLMs</h3>
                <p class="research-card-excerpt">
                    Can we find and manipulate specific "toxicity" features in language models?
                    A practical exploration of probing, ablation, and feature steering.
                </p>
                <div class="project-tags">
                    <span class="tag">Safety</span>
                    <span class="tag">Probing</span>
                    <span class="tag">Steering</span>
                </div>
            </div>
        </article>

    </div>
</section>